{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.utils import check_random_state\n",
    "from rcv_distribution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calculate_pair_mentions(ballots: np.ndarray, num_candidates: int, num_ballots: int, num_ranks: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the number of times each pair of candidates is mentioned together in the ballots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ballots : numpy.ndarray\n",
    "        An array representing the ranked votes. Each row is a ballot, with candidates represented by their indices.\n",
    "    num_candidates : int\n",
    "        The total number of unique candidates.\n",
    "    num_ballots : int\n",
    "        The total number of ballots.\n",
    "    num_ranks : int\n",
    "        The total number of ranks in each ballot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A square matrix where the entry at row i and column j represents the number of times candidate i and candidate j are mentioned together in the ballots.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a zero matrix to store the counts of pair mentions\n",
    "    pair_mentions = np.zeros((num_candidates, num_candidates))\n",
    "    \n",
    "    # For each ballot\n",
    "    for i in range(num_ballots):\n",
    "        # For each rank in the ballot\n",
    "        for j in range(num_ranks):\n",
    "            # For each other rank in the ballot\n",
    "            for k in range(num_ranks):\n",
    "                # If either of the candidates in the rank is invalid \n",
    "                if np.isnan(ballots[i, j]) or np.isnan(ballots[i, k]):\n",
    "                    continue\n",
    "                # Else increment the count for the rank pair\n",
    "                pair_mentions[int(ballots[i, j]) - 1, int(ballots[i, k]) - 1] += 1\n",
    "\n",
    "    return pair_mentions\n",
    "\n",
    "\n",
    "def plot_rcv_analysis(mds_1d_coordinates: dict, mds_2d_coordinates, most_common_order: tuple, all_order_frequencies: list, candidate_names: list) -> None:\n",
    "    \"\"\"\n",
    "    Plot the ranked-choice-voting (RCV) analysis results.\n",
    "\n",
    "    This function creates two plots:\n",
    "    1. A bar plot showing the frequencies of candidate orders.\n",
    "    2. A scatter plot showing the average MDS-1D coordinates for the most common order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    avg_1d_values_dict : dict\n",
    "        A dictionary mapping candidate order to average MDS-1D coordinates.\n",
    "    most_common_order : tuple\n",
    "        A tuple representing the most common order of candidates.\n",
    "    all_order_frequencies : list\n",
    "        A list of tuples, each containing a candidate order and its frequency.\n",
    "    candidate_names : list\n",
    "        A list of candidate names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Plot frequencies of all orders\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    orders, frequencies = zip(*all_order_frequencies)\n",
    "    orders = [\"-\".join(candidate_names[i] for i in order) for order in orders]\n",
    "    plt.barh(orders, frequencies)\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.title(\"Frequencies of Candidate Orders\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot average MDS-1D coordinates for most common order\n",
    "    mds_1d_coordinates = mds_1d_coordinates[most_common_order]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(np.zeros_like(mds_1d_coordinates), mds_1d_coordinates)\n",
    "    for i in range(len(candidate_names)):\n",
    "        plt.text(0.2, mds_1d_coordinates[i], candidate_names[most_common_order[i]])\n",
    "    plt.axis([-1, 1.5, mds_1d_coordinates.min() * 1.2, mds_1d_coordinates.max() * 1.2])\n",
    "    plt.ylabel(\"MDS-1D Coordinate\")\n",
    "    plt.title(\"Average MDS-1D Coordinates for Most Common Order\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def perform_rcv_analysis(csv_file: str, n_runs: int, random_state: Optional[int] = None, ignore_values: Optional[List[str]] = None, metric: bool = True) -> Tuple[Dict, Tuple, List, List]:\n",
    "    \"\"\"\n",
    "    Perform ranked-choice-voting (RCV) analysis on a CSV file of ballots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        The path to the CSV file containing ballots.\n",
    "    n_runs : int\n",
    "        The number of MDS runs to perform.\n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        Determines random number generation for centroid initialization. Use an int to make the randomness deterministic.\n",
    "    ignore_values : list, optional\n",
    "        A list of values to ignore when reading the CSV file. Defaults to common non-candidate values.\n",
    "    metric : bool, default=True\n",
    "        If True, perform metric MDS; otherwise, perform nonmetric MDS.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing the following elements:\n",
    "        - mds_1d_coordinates : A dictionary mapping candidate order to average MDS coordinates.\n",
    "        - mds_2d_coordinates : A dictionary mapping candidate order to average MDS coordinates for 2 dimensions. (TODO)\n",
    "        - most_common_order : The most common order of candidates.\n",
    "        - order_frequencies : A list of tuples, each containing a candidate order and its frequency.\n",
    "        - candidate_names : A list of candidate names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default values to ignore when reading CSV\n",
    "    if ignore_values is None:\n",
    "        ignore_values = ['(WRITE-IN)', 'WRITE-IN', 'writein', 'Write-In', 'Write-in', 'skipped', 'overvote', 'Undeclared', 'undervote']\n",
    "\n",
    "\n",
    "    # Load the CSV file and filter to keep only the 'rank' columns\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    df = df.filter(regex='^rank')\n",
    "\n",
    "    # Replace non-candidate values with None\n",
    "    for ignore_value in ignore_values:\n",
    "        df.replace(to_replace=re.compile(ignore_value), value=None, regex=True, inplace=True)\n",
    "\n",
    "    # Create a list of all candidate names and convert names to integer codes\n",
    "    raw_ballots = df.values.tolist()\n",
    "    candidate_names = [name for name in pd.unique(df.values.ravel()) if pd.notna(name)]\n",
    "    candidate_dict = {name: i for i, name in enumerate(candidate_names)}\n",
    "    num_candidates = len(candidate_names)\n",
    "\n",
    "    # Convert ballots to integers representing candidates, replacing invalid candidates with NaN\n",
    "    ballots = [[candidate_dict.get(candidate, np.nan) for candidate in ballot] for ballot in raw_ballots]\n",
    "    ballots = np.array(ballots)\n",
    "\n",
    "    # Count up frequencies of consecutive-pair ballot choices\n",
    "    num_ballots, num_ranks = ballots.shape\n",
    "    counts = np.zeros((num_candidates, num_candidates))\n",
    "    for i in range(num_ballots):\n",
    "        for j in range(num_ranks - 1):\n",
    "            if np.isnan(ballots[i, j]) or np.isnan(ballots[i, j+1]):\n",
    "                continue\n",
    "            counts[int(ballots[i, j]), int(ballots[i, j+1])] += 1\n",
    "\n",
    "    # Calculate pair mentions and normalize to frequencies relative to votes cast for the two candidates\n",
    "    mentioned_together = calculate_pair_mentions(ballots, num_candidates, num_ballots, num_ranks)\n",
    "    frequencies = counts / mentioned_together\n",
    "\n",
    "    # Combine frequencies in either direction to create symmetric matrix\n",
    "    freq_upper_triangle = np.zeros((num_candidates, num_candidates))\n",
    "    for i in range(num_candidates):\n",
    "        for j in range(i+1, num_candidates):\n",
    "            freq_upper_triangle[i, j] = (frequencies[i, j] + frequencies[j, i]) / 2\n",
    "            freq_upper_triangle[j, i] = freq_upper_triangle[i, j]\n",
    "\n",
    "    # Compute distance metric\n",
    "    min_freq = np.min(freq_upper_triangle[freq_upper_triangle > 0])\n",
    "    distance = 1 / np.sqrt(freq_upper_triangle)\n",
    "    distance[np.isnan(distance)] = 2 / min_freq\n",
    "    distance[np.isinf(distance)] = 2 / min_freq\n",
    "    np.fill_diagonal(distance, 0)\n",
    "\n",
    "    # Initialize random state\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    # Initialize containers for multiple MDS runs\n",
    "    all_orders = defaultdict(lambda: 0)\n",
    "    mds_1d_coordinates = defaultdict(list)\n",
    "    mds_2d_coordinates = defaultdict(list)\n",
    "\n",
    "    # Run multidimensional scaling multiple times\n",
    "    for _ in range(n_runs):\n",
    "\n",
    "        # Perform nonmetric multidimensional scaling\n",
    "        try:\n",
    "            mds_1d = MDS(n_components=1, metric=metric, max_iter=1000, random_state=random_state, dissimilarity='precomputed', normalized_stress='auto')\n",
    "            mds_2d = MDS(n_components=2, metric=metric, max_iter=1000, random_state=random_state, dissimilarity='precomputed', normalized_stress='auto')\n",
    "        except TypeError:\n",
    "            mds_1d = MDS(n_components=1, metric=metric, max_iter=1000, random_state=random_state, dissimilarity='precomputed')\n",
    "            mds_2d = MDS(n_components=2, metric=metric, max_iter=1000, random_state=random_state, dissimilarity='precomputed')\n",
    "\n",
    "        # Fit and transform the distance matrix\n",
    "        values_1d = mds_1d.fit_transform(distance)\n",
    "        values_2d = mds_2d.fit_transform(distance)\n",
    "\n",
    "        # Identify orders in 1D and 2D TODO Procrustes alignment for 2d ordering\n",
    "        order_1d = tuple(np.argsort(values_1d.flatten()))\n",
    "        order_2d = tuple(np.lexsort(values_2d.T))\n",
    "\n",
    "        # Store orders and MDS coordinates\n",
    "        all_orders[tuple(order_1d)] += 1\n",
    "        mds_1d_coordinates[order_1d].append(values_1d.flatten()[np.array(order_1d)])\n",
    "        mds_2d_coordinates[order_2d].append(values_2d.flatten()[np.array(order_2d)])\n",
    "\n",
    "    # Find most common order and frequencies of all orders along single dimension\n",
    "    temporary_orders = list(all_orders.keys())\n",
    "    for order in temporary_orders:\n",
    "        reversed_order = tuple(reversed(order))\n",
    "        if reversed_order in all_orders:\n",
    "            all_orders[order] += all_orders[reversed_order]\n",
    "            del all_orders[reversed_order]\n",
    "    order_counter = Counter(all_orders)\n",
    "    most_common_order = order_counter.most_common(1)[0][0]\n",
    "    order_frequencies = order_counter.most_common()\n",
    "\n",
    "    # Calculate average MDS coordinates for each unique order\n",
    "    mds_1d_coordinates = {order: np.mean(values, axis=0) for order, values in mds_1d_coordinates.items()}\n",
    "\n",
    "    return mds_1d_coordinates, mds_2d_coordinates, most_common_order, order_frequencies, candidate_names\n",
    "\n",
    "\n",
    "def get_distances_normalized(most_common_order: tuple, mds_1d_coordinates: Dict[tuple, np.ndarray], candidate_names: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Normalize the distances of MDS-1D coordinates for the most common order to start from 0 and ends at the number of candidates.\n",
    "    Return a dictionary with candidate names as keys and normalized distances as values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    most_common_order : tuple\n",
    "        A tuple representing the most common order of candidates.a\n",
    "    mds_1d_coordinates : dict\n",
    "        A dictionary mapping candidate order to average MDS-1D coordinates.\n",
    "    candidate_names : list\n",
    "        A list of candidate names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping candidate names to normalized MDS-1D coordinates.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the MDS-1D coordinates for the most common order\n",
    "    mds_1d_coordinates_common_order = mds_1d_coordinates[most_common_order]\n",
    "    \n",
    "    # Compute the min and max of the MDS-1D coordinates\n",
    "    min_val = np.min(mds_1d_coordinates_common_order)\n",
    "    max_val = np.max(mds_1d_coordinates_common_order)\n",
    "\n",
    "    # Compute the normalized MDS-1D coordinates (shifted so that they start from 0 and end at the number of candidates)\n",
    "    mds_1d_coordinates_common_order_normalized = ((mds_1d_coordinates_common_order - min_val) / (max_val - min_val)) * (len(candidate_names) - 1)\n",
    "    \n",
    "    # Create a dictionary with candidate names as keys and normalized distances as values\n",
    "    normalized_coordinates_dict = {candidate_names[most_common_order[i]]: mds_1d_coordinates_common_order_normalized[i] for i in range(len(most_common_order))}\n",
    "    \n",
    "    return normalized_coordinates_dict\n",
    "\n",
    "\n",
    "def perform_rcv_and_normalize(csv_file: str, n_runs: int = 1000) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Perform the ranked-choice-voting (RCV) analysis and normalize the distances of MDS-1D coordinates.\n",
    "    Return a dictionary with candidate names as keys and normalized distances as values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        The name of the CSV file to perform the RCV analysis on.\n",
    "    n_runs : int\n",
    "        The number of runs for the RCV analysis.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping candidate names to normalized MDS-1D coordinates.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform the RCV analysis\n",
    "    mds_1d_coordinates, mds_2d_coordinates, most_common_order, order_frequencies, candidate_names = perform_rcv_analysis(csv_file, n_runs)\n",
    "    \n",
    "    # Normalize the distances\n",
    "    normalized_coordinates_dict = get_distances_normalized(most_common_order, mds_1d_coordinates, candidate_names)\n",
    "    \n",
    "    return normalized_coordinates_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
